{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datascience import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "logs_dir = '/Users/leviharris/Library/CloudStorage/GoogleDrive-leviharris555@gmail.com/Other computers/mac_new/NBA_HUDL_data/nba-plus-statvu-dataset/hudl-game-logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of video paths\n",
    "base_video_dir = '/Users/leviharris/Library/CloudStorage/GoogleDrive-leviharris555@gmail.com/Other computers/mac_new/NBA_HUDL_data/nba-plus-statvu-dataset/game-replays/720'\n",
    "all_videos = [os.path.join(base_video_dir, f) for f in os.listdir(base_video_dir)]\n",
    "videos_map = {}\n",
    "\n",
    "for v in all_videos:\n",
    "    split = v.split('_')\n",
    "    game_id = split[3].split('/')[-1]\n",
    "    quarter = split[-1][6]\n",
    "    uni_id = game_id + '_' + quarter\n",
    "    videos_map[uni_id] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_shot(s):\n",
    "    legal_strings = ['2+', '2-', '3+', '3-']\n",
    "    return s in legal_strings\n",
    "\n",
    "def is_made(s):\n",
    "    if '+' in s:\n",
    "        return True\n",
    "    else: return False \n",
    "\n",
    "def get_shot_attempts(fp):\n",
    "\n",
    "    # gather all shot attempts\n",
    "    full_table = Table.from_df(pd.read_csv(fp, delimiter=';'))\n",
    "    shot_attempts = full_table.with_column(\n",
    "        'is_shot', \n",
    "        [is_shot(i) for i in full_table.column('action_name')],\n",
    "    ).where('is_shot', are.equal_to(True)).select(['action_name', 'half', 'second'])\n",
    "\n",
    "    # add columns\n",
    "    shot_attempts = shot_attempts.with_columns(\n",
    "        'is_made', [is_made(i) for i in shot_attempts.column('action_name')],\n",
    "        'game_id', np.repeat(fp.split('.')[-2], shot_attempts.num_rows)\n",
    "    )\n",
    "\n",
    "    # add unified game qaurter string ids\n",
    "    uni_ids = []\n",
    "    for quarter, game_id in zip(shot_attempts.column('half'), shot_attempts.column('game_id')):\n",
    "        uni_id = str(game_id) + '_' + str(quarter)\n",
    "        uni_ids.append(uni_id)\n",
    "\n",
    "    # append video paths to table\n",
    "    video_paths = []\n",
    "    for id in uni_ids:\n",
    "        if id in videos_map:\n",
    "            video_paths.append(videos_map[id])\n",
    "        else:\n",
    "            video_paths.append(None)\n",
    "\n",
    "    shot_attempts: Table = shot_attempts.drop('game_id').drop('half').with_column(\n",
    "        'video_path', video_paths\n",
    "    ).with_column(\n",
    "        'uni_id', uni_ids\n",
    "    )\n",
    "    return shot_attempts.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. filter through hudl logs and concatinate all shot attempts into a table\n",
    "# 2. match each shot attempt with its corresponding video path and timestamps\n",
    "# 3. extract all shot attempts\n",
    "\n",
    "logs = [os.path.join(logs_dir, f) for f in os.listdir(logs_dir)]\n",
    "all_shot_attempts = None\n",
    "\n",
    "# concatinate all logs together\n",
    "for log_path in tqdm.tqdm(logs):\n",
    "    if all_shot_attempts is None:\n",
    "        all_shot_attempts = get_shot_attempts(log_path)\n",
    "    else:\n",
    "        all_shot_attempts = pd.concat([all_shot_attempts, get_shot_attempts(log_path)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datasceince table, filter out all missing videos\n",
    "all_shot_attempts_table = Table.from_df(all_shot_attempts).where('video_path', are.not_equal_to(None))\n",
    "all_shot_attempts_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "database_path = '/Users/leviharris/Library/CloudStorage/GoogleDrive-leviharris555@gmail.com/My Drive/research/datasets/nba-pre-shot-attempts'\n",
    "\n",
    "def create_new_clip(row, database_dir):\n",
    "    \"\"\"\n",
    "    Given a shot attempt row and dataset path, save a new clip to the\n",
    "    corresponding 'make' or 'miss' subdirectory.\n",
    "    \"\"\"\n",
    "\n",
    "    # game id info from row object\n",
    "    attempt = str(row[0])\n",
    "    timestamp = str(row[1])\n",
    "    is_made = 'make' if row[2] else 'miss'\n",
    "    video_path = str(row[3])\n",
    "    uni_id = str(row[4])\n",
    "\n",
    "    # game name and dst path\n",
    "    name = 'uni_id_' + uni_id + '.' + 'points_' + attempt + '.timestamp_' + timestamp + '_' + '.mp4'\n",
    "    dst_path = os.path.join(database_dir, is_made, name)\n",
    "\n",
    "    # open cv2 capture object\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    if not capture.isOpened():\n",
    "        raise Exception(f'Could not open video at path {dst_path}!')\n",
    "    \n",
    "    # create a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "    writer = cv2.VideoWriter(\n",
    "        dst_path,\n",
    "        fourcc,\n",
    "        fps,\n",
    "        (224, 224)\n",
    "    )\n",
    "    \n",
    "    # calculate the starting frame of the shot attempt\n",
    "    # actual clip start - six seconds\n",
    "    clip_start_frame = int((float(timestamp) * fps) - (fps * 5.0))\n",
    "\n",
    "    # each clip will be three seconds in length\n",
    "    clip_duration = fps * 3\n",
    "    clip_end_frame = int(clip_start_frame + clip_duration)\n",
    "\n",
    "    # set the video reader to starting frame of clip\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, clip_start_frame)\n",
    "\n",
    "    # write resized frames to clip out path\n",
    "    for index in range(clip_start_frame, clip_end_frame):\n",
    "        ret, frame = capture.read()\n",
    "\n",
    "        # resize frame to (224x224)\n",
    "        resized_frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "        writer.write(resized_frame)\n",
    "\n",
    "    # release writer/reader objects\n",
    "    capture.release()\n",
    "    writer.release()\n",
    "\n",
    "for row in tqdm.tqdm(all_shot_attempts_table.rows):\n",
    "    try:\n",
    "        create_new_clip(row, database_path)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.79"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gb = 1000mb\n",
    "# mb = 1000kb\n",
    "\n",
    "((103000 * 930) / 1000) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporal-grounding-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
