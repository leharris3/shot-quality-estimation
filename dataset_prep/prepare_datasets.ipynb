{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_dataset import split_dataset\n",
    "from format_data_kinetics_tf import clean_directory, format_dataset_kinetics\n",
    "from extract_shot_attempts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "src_dir = '/playpen-storage/levlevi/contextualized-shot-quality-analysis/data/experiments/test-sets/result-shown/result_shown_test_nba_3.6k_4s'\n",
    "dst_dir = '/playpen-storage/levlevi/contextualized-shot-quality-analysis/data/experiments/test-sets/result-shown/result_shown_test_nba_1k_4s'\n",
    "\n",
    "split_dataset(\n",
    "    src_dir=src_dir,\n",
    "    dst_dir=dst_dir,\n",
    "    num_clips=1000\n",
    ")\n",
    "\n",
    "# clean_directory(dst_dir)\n",
    "# format_dataset_kinetics(dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:04<00:00, 418.65it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def copy_file(args, progress_bar=None):\n",
    "    \"\"\"\n",
    "    Copy a single file from (src, dst)\n",
    "    \"\"\"\n",
    "\n",
    "    src, dst = args\n",
    "    shutil.copy2(src, dst)\n",
    "    if progress_bar:\n",
    "        progress_bar.update(1)\n",
    "\n",
    "\n",
    "def copy_and_split_dataset(\n",
    "    train_val_dir: str,\n",
    "    test_dir: str,\n",
    "    dst_dir: str,\n",
    "    num_files_to_copy: int,\n",
    "    class_split=None,\n",
    "):\n",
    "\n",
    "    # default 90/10 train/val\n",
    "    if class_split is None:\n",
    "        class_split = [0.9, 0.1]\n",
    "\n",
    "    all_src_file_paths = []\n",
    "    for root, _, files in os.walk(train_val_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp4\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                all_src_file_paths.append(file_path)\n",
    "\n",
    "    made_file_paths = []\n",
    "    missed_file_paths = []\n",
    "\n",
    "    for index, src_file_path, in enumerate(all_src_file_paths):\n",
    "        file_name = os.path.basename(src_file_path)\n",
    "        file_class = os.path.basename(os.path.dirname(src_file_path))\n",
    "\n",
    "        # a clever way of splitting exactly into 90/10 train/val\n",
    "        split_dir = \"val\" if index % int(class_split[0] * 10) == 0 else \"train\"\n",
    "        dst_file_path = os.path.join(dst_dir, split_dir, file_class, file_name)\n",
    "\n",
    "        if file_class == 'made':\n",
    "            made_file_paths.append([src_file_path, dst_file_path])\n",
    "        elif file_class == 'missed':\n",
    "            missed_file_paths.append([src_file_path, dst_file_path])\n",
    "\n",
    "    random.shuffle(made_file_paths)\n",
    "    random.shuffle(missed_file_paths)\n",
    "    all_copy_opperations = made_file_paths[0: num_files_to_copy // 2] + missed_file_paths[0: num_files_to_copy // 2]\n",
    "\n",
    "    # add all file paths from the test folder\n",
    "    for root, _, files in os.walk(test_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp4\"):\n",
    "                src_test_file_path = os.path.join(root, file)\n",
    "                file_name = os.path.basename(src_test_file_path)\n",
    "                file_class = os.path.basename(os.path.dirname(src_test_file_path))\n",
    "                split_dir = \"test\"\n",
    "                dst_test_file_path = os.path.join(dst_dir, split_dir, file_class, file_name)\n",
    "                all_copy_opperations.append([src_test_file_path, dst_test_file_path])\n",
    "\n",
    "    split_dirs = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    # make new train/val/test dirs\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    for split_dir in split_dirs:\n",
    "        new_dir = os.path.join(dst_dir, split_dir)\n",
    "        os.makedirs(new_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(new_dir, \"made\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(new_dir, \"missed\"), exist_ok=True)\n",
    "\n",
    "    progress_bar = tqdm(total=len(all_copy_opperations))\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        for copy_operation in all_copy_opperations:\n",
    "            executor.submit(copy_file, copy_operation, progress_bar=progress_bar)\n",
    "\n",
    "copy_and_split_dataset(\n",
    "    train_val_dir=\"/playpen-storage/levlevi/contextualized-shot-quality-analysis/data/experiments/results-shown/result_shown_nba_52k_8s\",\n",
    "    test_dir=\"/playpen-storage/levlevi/contextualized-shot-quality-analysis/data/experiments/test-sets/result-shown/result_shown_test_nba_1k_8s\",\n",
    "    dst_dir=\"/playpen-storage/levlevi/contextualized-shot-quality-analysis/data/experiments/results-shown/result_shown_nba_1k_8s\",\n",
    "    num_files_to_copy=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shot-loc-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
